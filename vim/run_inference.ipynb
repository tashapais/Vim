# Import necessary libraries
import torch
from torchvision import transforms
from PIL import Image

# Assuming the model initialization function is correctly imported from your model definition file
from models_mamba import vim_tiny_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2

def load_model():
    # Initialize the model with the specific architecture that matches the checkpoint
    model = vim_tiny_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2(pretrained=False, bimamba_type="v2", if_devide_out=True)
    model.eval()  # Set the model to evaluation mode

    # Load the model weights
    checkpoint_path = '/common/home/tdp74/robotics/Vim/checkpoints/Vim-tiny-midclstok/vim_t_midclstok_76p1acc.pth'
    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))
    model.load_state_dict(checkpoint['model'], strict=True)

    # Move model to GPU if available
    if torch.cuda.is_available():
        model = model.cuda()
    
    return model

def prepare_input(image_path):
    # Define the image transformations
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # Load and transform the image
    image = Image.open(image_path)
    image = transform(image).unsqueeze(0)  # Add batch dimension

    if torch.cuda.is_available():
        image = image.cuda()  # Move the data to GPU if available
    
    return image

def run_inference(model, image):
    with torch.no_grad():  # Disable gradient calculation
        output = model(image)
    return output

# Main function to execute the workflow
def main():
    model = load_model()
    image_path = '/common/home/tdp74/robotics/imagenet-1k/val/n01440764/'
    image = prepare_input(image_path)
    output = run_inference(model, image)
    print("Inference output:", output)

if __name__ == "__main__":
    main()
